---
title: "GoFordProj"
author: "Team"
date: "4/24/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE, message = FALSE, warning = FALSE, root.dir = '/tmp')
```

## Loading necessary libraries.

```{r cars}
library(data.table)
#draw plots
library(ggplot2)
#google maps
library(ggmap)
library(dplyr)
# String manipulation
library(stringr)
# Parsing of HTML/XML files  
library(rvest)
# Eases DateTime manipulation
library(lubridate)
library(tidyr)
library(geosphere)
library(leaflet)
library(RColorBrewer)
library(shiny)
library(tidyr)
library(geosphere)
library(rsconnect)
```




```{r}

# bikedata17 = fread("2017-fordgobike-tripdata.csv", stringsAsFactors = F)
# bikedata181 = fread("201801_fordgobike_tripdata.csv", stringsAsFactors = F)
# bikedata182 = fread("201802_fordgobike_tripdata.csv", stringsAsFactors = F)
# bikedata183 = fread("201803_fordgobike_tripdata.csv", stringsAsFactors = F)
#fread() is part of the data.table package in R and they perform significantly faster than the base read.csv() and write.csv() functions.


#Combine all the csv files together, fread function is part of pacakge datatable
bikedata <- rbindlist(lapply(c("2017-fordgobike-tripdata.csv","201801_fordgobike_tripdata.csv","201802_fordgobike_tripdata.csv","201803_fordgobike_tripdata.csv"),fread,stringsAsFactors = F))

# class(bikedata),summary(bikedata) now instead of data.frame, our bikedata is a data.table 

#Have the start and end times be read as dates. 
bikedata$start_time <- ymd_hms(bikedata$start_time)
bikedata$end_time <- ymd_hms(bikedata$end_time)

#Create new column Date for the future use of merging weather data,
bikedata$Date <- date(bikedata[,start_time])

#I am not sure how the fordbike charge, to make it simple, always round up duration to the nearest whole minute
#
#round(as.numeric(bikedata$duration_sec)/60, digits = 1)
bikedata$duration_min <-ceiling(as.numeric(bikedata$duration_sec)/60)
#delete bikedata$duration_sec
bikedata$duration_sec <-NULL
#See the date range
range(bikedata$start_time)
```

## Upload weather data from weatherunderground.com

```{r }
#Upload all the weather data from weatherunderground.com

# page1 = "https://www.wunderground.com/history/airport/KSFO/2017/6/28/CustomHistory.html?dayend=31&monthend=3&yearend=2018&req_city=&req_state=&req_statename=&reqdb.zip=&reqdb.magic=&reqdb.wmo="
# 
# p1 = page1 %>%
#   read_html() %>%
#   html_nodes(xpath = '//*[@id="obsTable"]') %>%
#   html_table()

# Get the dataframe from the list
# weatherhist = p1[[1]]

# Too messy with extra rows of column names
# In the weatherhist data frame, the headers repeat each month, so we will need to clean that up. 
# Will also need to change how the date appears in the first column and rename to something besides "2017". 
# As the data is,it is just the number of the day with no association to which month. The month is only in the row header. 

# Try to rebuild the table by combining weather data in each month

# June only contain the last 3 days' data, so the url pattern is different
page176 = "https://www.wunderground.com/history/airport/KSFO/2017/6/28/CustomHistory.html?dayend=30&monthend=6&yearend=2017&req_city=&req_state=&req_statename=&reqdb.zip=&reqdb.magic=&reqdb.wmo="

# Other months could be collected via specific pattern url.
months_2017 = c(7,8,9,10,11,12)
months_2018 =c(1,2,3)

# Urls
url.base2017 <- "https://www.wunderground.com/history/airport/KSFO/2017/"
url.base2018 <- "https://www.wunderground.com/history/airport/KSFO/2018/"
url.end <- "/1/MonthlyHistory.html?req_city=&req_state=&req_statename=&reqdb.zip=&reqdb.magic=&reqdb.wmo="
urls2017 <- paste0(url.base2017,months_2017,url.end)
urls2018 <- paste0(url.base2018,months_2018,url.end)

# Lists of weather data
p17list <- lapply(c(page176,urls2017), function(i) {
    read_html(i) %>%
    html_nodes(xpath = '//*[@id="obsTable"]') %>%
    html_table()
})

p18list <- lapply(urls2018, function(i) {
    read_html(i) %>%
    html_nodes(xpath = '//*[@id="obsTable"]') %>%
    html_table()
})

# Change the column name and add Date
#2017
for ( i in 1:length(p17list)) {
  month <- p17list[[i]][[1]]
  names <- month[1,]
  names[,length(names)]<-""
  month <- month[-1,]
  coln <- colnames(month)
  colnames(month)<- paste(coln,"-",names)
  month$Date <- ymd(paste(colnames(month)[1],month[,1]))
  p17list[[i]][[1]]<- month[,-1]
}
#2018
for ( i in 1:length(p18list)) {
  month <- p18list[[i]][[1]]
  names <- month[1,]
  names[,length(names)]<-""
  month <- month[-1,]
  coln <- colnames(month)
  colnames(month)<- paste(coln,"-",names)
  month$Date <- ymd(paste(colnames(month)[1],month[,1]))
  p18list[[i]][[1]]<- month[,-1]
}

# Combine the new table as weatherhist
p17list2 <- do.call(rbind, p17list)
final17 <- do.call(rbind, p17list2)
p18list2 <- do.call(rbind, p18list)
final18 <- do.call(rbind, p18list2)
weatherhist <- rbind(final17,final18)

#reset the row index
rownames(weatherhist) <- NULL

#Change variables from char to num
weatherhist[,1:19]<- apply(weatherhist[,1:19],2,function(x) as.numeric(x))

#Create some extra events
weatherhist$`Events - `[weatherhist$`Temp. (°F) - high` >80 & weatherhist$`Humidity (%) - high` > 40 & weatherhist$`Precip. (in) - sum` == 0] = "Hot"
weatherhist$`Events - `[weatherhist$`Temp. (°F) - high` >88 & weatherhist$`Humidity (%) - high` > 50 & weatherhist$`Precip. (in) - sum` == 0] = "Extreme Hot"
weatherhist$`Events - `[weatherhist$`Temp. (°F) - avg` < 55 & weatherhist$`Wind (mph) - avg` > 10 & weatherhist$`Precip. (in) - sum` == 0] = "Cold"
weatherhist$`Events - `[is.na(weatherhist$`Events - `) | weatherhist$`Events - ` == ""] = "Normal"
#Create some extre event like 

#Switch the Date column to the first and delete unnecessary columns

weatherhist = weatherhist %>% select(Date, colnames(weatherhist)[c(2,5,8,11,14,17,19,20)])
#weatherhist = weatherhist %>% select(Date, everything())
write.csv(weatherhist, file="weatherhist.csv")
```

# Merge fordbike and weather data into one table.

```{r}
all_data <- merge(bikedata, weatherhist, by.x = 'Date', by.y = 'Date')
```


Evaluate how weather (temperature and/or precipitation) impact the number of rides per day or the duration of the ride?
a.	If so, should Ford add incentive programs on rainy days to mitigate lost revenue?

```{r}

# Convert "user_type","member_gender","Events - "to factor, and member_birth_year to numeric
all_data$user_type <-factor(all_data$user_type)
all_data$member_gender <- factor(all_data$member_gender)
all_data$`Events - ` <- factor(all_data$`Events - `)
all_data$member_birth_year <- as.numeric(all_data$member_birth_year)
summary(all_data$`Events - `)
# Buil a bar plot to see the whether daily average temperature influences ride duration among different user type
bike_temp <- all_data %>%
  select(colnames(all_data)[c(13,16,17)]) %>%
  group_by(`Temp. (°F) - avg`,user_type)%>%
  summarise(avg_duration=round(mean(duration_min),1))

  ggplot(data = bike_temp, 
         mapping= aes(x=factor(`Temp. (°F) - avg`),
                      y = avg_duration,
                      fill= user_type))+
  geom_col(position = 'dodge',width = 1,color="white")+
  labs(x='Temperature',y='Average Duration',fill="User Type", title= "Average Rental Duration under Different Temperature")
```

```{r}


# Subscribers and customers both show no significant difererence on the duration regarding different temperatures. However, customers tend to rent bikes about three times longer than those subscribers do.
# 
# How about usage?

  
bike_temp_u  <- all_data %>%
  select(colnames(all_data)[c(13,16,17)]) %>%
  group_by(`Temp. (°F) - avg`,user_type)%>%
  summarise(usage=n())

  ggplot(data = bike_temp_u, 
         mapping= aes(x=factor(`Temp. (°F) - avg`),
                      y = usage,
                      fill= user_type))+
  geom_col(position = 'dodge',width = 1,color="white")+
  labs(x='Temperature',y='Usage',fill="User Type", title= "Total Usage under Different Temperature")
  
#Interestingly, Subscribers tend to use the bike much more often than customers do. Also, we notice that in the specific range of temperatue, both types of users tend to rent bikes more often. From the chart we can estimate is from 51 - 67.
```

```{r}
#We might think if weather is associated with months since different seasons might also influence the flow of tourist and bike usage.
bike_months <- all_data %>%
  select(colnames(all_data)[c(1,13,16,17)]) %>%
  mutate(Month = lubridate::month(Date,label=T)) %>%
  filter(Month!="Jun")%>% # Only two days in June, so I exclude the two days.
  group_by(Month)%>%
  summarise(monthly_avg_temp=round(mean(`Temp. (°F) - avg`)),usage=n())

#Reorder the sequence of month by real month order from July,2017 to March,2018
levels =levels(factor(bike_months$Month))
bike_months$Month<-factor(bike_months$Month,levels[c(4:12,1:3)])

  ggplot(data = bike_months, 
         mapping= aes(x=factor(Month),
                      y = usage))+
  geom_col()+
  geom_text(aes(label = monthly_avg_temp), vjust = 0, color = "red")+
  labs(x='Month',y='Average Duration',title = "Monthly Bike Usage Growth and Average Monthly Temperature")


```

```{r}


# Beginning operation in August 2013 as Bay Area Bike Share, the Ford GoBike system currently has 2,500 bicycles in 260 stations across San Francisco, East Bay and San Jose. On June 28, 2017, the system officially launched as Ford GoBike in a partnership with Ford Motor Company.

# Although we can tell trends from the plot that during winter and summer, the usage is less than other seasons. However it is hard to make this conclusion because fordbike system officially launched on june 28,2017. We might expect a rapid growth among the first few months.

#check what we have in the events
levels(all_data$`Events - `)


# Event Vs average daily Usage
bike_event = all_data%>%
  select('Date','user_type','duration_min',`Events - `)%>%
  mutate(Month = month(Date)) %>%
  group_by(`Events - `, Date, user_type) %>%
  summarise(usage= n())

bike_event %>%
  group_by(`Events - `,user_type) %>%
  summarise(avg = mean(usage)) %>%
  ggplot(aes(x=`Events - ` , y = avg, fill= user_type))+
  geom_col(position = 'dodge') +
  labs(x='Events',y='Average Daily Usage', fill="User Type", title= "Average Daily Usage under Different Events")


```

```{r}
#Event VS average daily duration
bike_event2 = all_data%>%
  select('Date','user_type','duration_min',`Events - `)%>%
  #mutate(Month = month(Date)) %>%
  group_by(`Events - `, Date, user_type) %>%
  summarise(avg_duration= mean(duration_min))

bike_event2 %>%
  ggplot(aes(x=`Events - ` , y = avg_duration, fill= user_type))+
  geom_col(position = 'dodge') +
  labs(x='Events',y='Average Daily Duration',fill="User Type", title= "Average Daily Duration under Different Events")


```

```{r}

#Usage Growth over time
all_data %>%
  select(Date,user_type,duration_min) %>%
  group_by(Date)%>%
  summarise(count=n())%>%
  ggplot(aes(x= Date, y = count))+
  geom_line()+
  scale_x_date(date_breaks = "1 month")+
  theme(axis.text.x = element_text(angle = 60, hjust = 1))


```


```{r}
# Reading all data downloaded form the Ford Bike site
bikedata17 = read.csv("2017-fordgobike-tripdata.csv")
bikedata18_1 = read.csv("201801_fordgobike_tripdata.csv")
bikedata18_2 = read.csv("201802_fordgobike_tripdata.csv")
bikedata18_3 = read.csv("201803_fordgobike_tripdata.csv")

# Combine them into Single data
Bikedata=rbind(bikedata17,
               bikedata18_1,
               bikedata18_2,
               bikedata18_3)

# Data cleaning for the start and end time 
finalbikedata = Bikedata%>%
  separate(col= start_time,
           into = c("start_Time","Junk1"),
           sep = 19,remove = T )%>%
  separate(col= end_time,
           into = c("end_Time","Junk2"),
           sep = 19,remove = T )

#Removing Junk Created
finalbikedata = finalbikedata[,-c(3,5)]  
  
#Formatting date and Time using Lubridate
finalbikedata$start_Time = ymd_hms(finalbikedata$start_Time)
finalbikedata$end_Time = ymd_hms(finalbikedata$end_Time)
```


```{r}
### For Spider Map
## Compile data specific for spider map
Spiderdata=finalbikedata%>%
  filter(start_station_id %in% c(3,5,144))%>% ## Input to be given from Shiny, with multiple select od start station_id
  group_by(start_station_id,
           start_station_longitude,
           start_station_latitude,
           end_station_id,
           end_station_longitude,
           end_station_latitude)%>%
  summarise(count=n())%>%
  filter(count>= 100)## Input from Shiny , with slider bar giving rang of frequency 


##Consolidate into flow pattern for path lines , 
##To compute distances for angular (longitude/latitude) locations

flows <- gcIntermediate(Spiderdata[,2:3],
                        Spiderdata[,5:6],
                        sp = TRUE,
                        addStartEnd = TRUE)

flows$count <- Spiderdata$count/100
flows$start_station_id <- Spiderdata$start_station_id
flows$end_station_id <- Spiderdata$end_station_id

##Creating spider MAp

##To create label on the line
hover <- paste0(flows$start_station_id, " to ", 
                flows$end_station_id, ': ', 
                as.character(flows$count*100))

## To map origin stations to colours as there are too many 
pal <- colorFactor(brewer.pal(4, 'Set2'), flows$start_station_id)

##Creating Interactive Spider MAp
leaflet() %>%
  addProviderTiles('CartoDB.Positron') %>%
  addPolylines(data = flows, weight = ~count, label = hover, 
               group = ~start_station_id, color = ~pal(start_station_id)) %>%
  addLayersControl(overlayGroups = unique(flows$start_station_id), 
                   options = layersControlOptions(collapsed = FALSE))
```

```{r}
## Setup data to summarize day of the week

bikestartdays = finalbikedata %>%
mutate(dayweek = wday(start_Time, label = T, abbr = F), hourday = hour(start_Time)) %>%
group_by(dayweek, hourday) %>%
summarise(count = n())

bikeenddays = finalbikedata %>%
mutate(dayweek = wday(end_Time, label = T, abbr = F), hourday = hour(end_Time)) %>%
group_by(dayweek, hourday) %>%
summarise(count = n())

# Build heatmaps
ggplot(bikestartdays, aes(x = dayweek,
 y = factor(hourday),
 fill = count)) +
geom_tile(color = "black") +
scale_fill_gradient(low = "white", high = "darkgreen") +
 xlab("Day of week") +
 ylab("Hour of day") +
ggtitle("Heatmap of Start Times of Bike Renters") +
theme_minimal()

ggplot(bikeenddays, aes(x = dayweek,
y = factor(hourday),
fill = count)) +
geom_tile(color = "black") +
scale_fill_gradient(low = "white", high = "darkred") +
xlab("Day of week") +
ylab("Hour of day") +
ggtitle("Heatmap of Start Times of Bike Renters") +
theme_minimal()
```

```{r}
ui <- fluidPage(
  
  titlePanel("Ford bike Start Times usage"),
  sidebarLayout(
    sidebarPanel(
      helpText("Please select the start times days for which you want to see the bike usage heatmap"),
      checkboxGroupInput(inputId = "dayweekchoice1", 
                         label = "Day", 
                         choices = unique(bikestartdays$dayweek),
                         selected = unique(bikestartdays$dayweek))
      
    ), 
    mainPanel(
      plotOutput(outputId = "plot")
    )
  )
)

server <- function(input, output) {
  
  bikestartdaysin1=reactive({bikestartdays %>% 
      filter(dayweek %in% input$dayweekchoice1)})
  
  output$plot= renderPlot({ggplot(bikestartdaysin1(), aes(x = dayweek, 
                                                         y = factor(hourday), 
                                                         fill = count)) + 
      geom_tile(color = "black") + 
      scale_fill_gradient(low = "white", high = "darkgreen") +
      xlab("Day of week") +
      ylab("Hour of day") +
      ggtitle("Heatmap of Start Times of Bike Renters") +
      theme_minimal()})
  
  
}

shinyApp(ui, server)

```

```{r}


ui <- fluidPage(
  
  titlePanel("Ford bike End Times usage"),
  sidebarLayout(
    sidebarPanel(
      helpText("Please select the end times days for which you want to see the bike usage heatmap"),
      checkboxGroupInput(inputId = "dayweekchoice2", 
                         label = "Day", 
                         choices = unique(bikestartdays$dayweek),
                         selected = unique(bikestartdays$dayweek))
      
    ), 
    mainPanel(
      plotOutput(outputId = "plot")
    )
  )
)

server <- function(input, output) {
  
  bikestartdaysin2=reactive({bikestartdays %>% 
      filter(dayweek %in% input$dayweekchoice2)})
  
  output$plot= renderPlot({ggplot(bikeenddays, aes(x = dayweek, 
                                                   y = factor(hourday), 
                                                   fill = count)) + 
      geom_tile(color = "black") + 
      scale_fill_gradient(low = "white", high = "darkred") +
      xlab("Day of week") +
      ylab("Hour of day") +
      ggtitle("Heatmap of End Times of Bike Renters") +
      theme_minimal()})
  
  
}

shinyApp(ui, server)
```